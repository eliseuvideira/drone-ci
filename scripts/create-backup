#!/usr/bin/env bash

set -e
set -u
set -x

script_name="$(basename "$0")"
script_dir="$(realpath "$(dirname "$0")")"

usage() {
  echo "${script_name}: usage: ${script_name}" >&2
}

exit_with_error() {
  echo "${script_name}: error: $1" >&2
  usage
  exit 1
}

recieved_arguments="$#"
expected_arguments="0"

if [ "${recieved_arguments}" != "${expected_arguments}" ]; then
  exit_with_error "invalid number of arguments, expected \"${expected_arguments}\", recieved \"${recieved_arguments}\""
fi

temporary_file="$(mktemp)"
root_dir="$(realpath "${script_dir}/..")"
drone_dir="$(realpath "${root_dir}/drone")"
env_file="${root_dir}/.env"

extract_variable() {
  grep "^${1}=" "${2}" | sed -E "s/^${1}=(.*)$/\1/"
}

AWS_ACCESS_KEY_ID="$(extract_variable "AWS_ACCESS_KEY_ID" "${env_file}")"
AWS_SECRET_ACCESS_KEY="$(extract_variable "AWS_SECRET_ACCESS_KEY" "${env_file}")"
AWS_S3_REGION="$(extract_variable "AWS_S3_REGION" "${env_file}")"
AWS_S3_BUCKET="$(extract_variable "AWS_S3_BUCKET" "${env_file}")"

compress_file_to() {
  gzip --stdout --keep --verbose "$1" >"$2"
}

upload_file_to_storage() {
  docker run \
    --rm \
    --env "AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}" \
    --env "AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}" \
    --env "AWS_S3_REGION=${AWS_S3_REGION}" \
    --volume "/tmp:/tmp" \
    amazon/aws-cli \
    s3 cp "${1}" "${2}"
}

compress_file_to "${drone_dir}/database.sqlite" "${temporary_file}"

upload_file_to_storage "${temporary_file}" "${AWS_S3_BUCKET%/}/$(date +%Y)/$(date +%m)/$(date +%d)/database.sqlite.$(date +%s).gz"

trap 'rm -f -- "${temporary_file}"' EXIT
